# double-bootstrap

> 贝叶斯思维和对 Type II error rate 的考量让多重假设检验方法上升到了新的高度。

### Environment

Python3

### Background

概括来说，传统的多重假设检验方法均可以归纳到“正交化” + “bootstrap”两个技术的综合运用。以挖掘股票市场异象为情景来说，其中“正交化”的作用是在样本内剔除每个异象的超额收益；“bootstrap”则是在正交化后的基础上通过重采样更多的数据，以此获得仅由运气造成的异象超额收益显著性（t-statistic）的分布。

在得到由运气造成的显著性（t-statistic）的分布后，这些方法往往以控制事先约定的 Type I error rate（false discovery rate），例如常见的 5%，来选定 t-statistic 的阈值，并以此确定哪些异象能够获得显著的超额收益。

传统方法虽然简单易用，但是存在两个问题：

在“正交化”的过程中，往往会对所有异象都做“正交化”处理（原假设为异象超额收益为零）。然在现实中，这种处理方法忽视了先验的作用。对于待检验的诸多异象，人们可能根据金融学先验认为其中一定比例的异象的超额收益是显著的，但传统的方法并不能利用这种先验。
t-statistic 阈值是通过事先约定的 Type I error rate 确定的，而不去考虑 Type I 和 Type II 两类错误的 trade-off。这么做的结果是，传统多重假设检验方法的 Type II error rate 往往很高，power (= 1 – Type II error rate) 往往很低。举个极端的例子，假设某个算法把所有原假设都接受了，那么它也就没能发现任何真正的异象（power = 0）。
对研究异象来说，Type II error 意味着异象本身能够获得超额收益（原假设为假），但是检验并没有拒绝其原假设，因此错失了真正的异象。

尽管如此，常见方法仅仅关心 Type I error rate 也实在是无奈之举。这是因为哪怕对于单一假设检验，计算 Type II error rate 都并不容易，更不用说多重假设检验问题。如果想要计算 Type II error rate，就必须知道备择假设下参数的取值（本文附录部分引用了 Wikipedia 的例子说明如何在单一假设检验下计算 Type II error rate）。但显然，对于成百上千个异象来说，想要遍历它们备择假设下的预期超额收益不切实际。这个巨大的障碍使得人们难以将单一检验中计算 Type II error rate 的方法复制到多重假设检验问题中。

除了分析的难度，还有另一个原因是人们在过去通常认为 Type II error 的影响不如 Type I error 的影响大。以大幅提升分析难度为代价，换来的边际期望收益却有限，似乎有些得不偿失。不过，这种看法也逐渐在转变。在 α 越来越稀缺的当下，Type II error 的成本越来越高，让人开始重视两类错误之间的取舍。

在这种背景下，Harvey and Liu (2020) 提出了一个基于双重 bootstrap 的多重假设检验框架，同时解决了上述两个问题。
